{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lkevin2018/cog-320-lecture-examples/blob/main/nlp_resume_bert_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf441945",
      "metadata": {
        "id": "cf441945"
      },
      "source": [
        "# üß™ NLP Workshop: Fine-Tuning BERT on Resumes + Pushing to Hugging Face & GitHub\n",
        "\n",
        "In this live exercise, you'll:\n",
        "\n",
        "1. Load a **resume dataset** from Kaggle  \n",
        "2. Fine-tune a **BERT text classification model** on resume text  \n",
        "3. Do a **simple bias exploration** of the dataset using a pre-trained BERT-based model  \n",
        "4. Save the fine-tuned model as a **`.pt` file**  \n",
        "5. Push the model to a **private Hugging Face repo**  \n",
        "6. Push this notebook/code into **your own GitHub fork**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6152e8",
      "metadata": {
        "id": "0c6152e8"
      },
      "source": [
        "## ‚úÖ Step 0: Install required libraries\n",
        "\n",
        "Run this cell first.\n",
        "\n",
        "We‚Äôll use:\n",
        "\n",
        "- `transformers` ‚Äì BERT models & training utilities  \n",
        "- `datasets` ‚Äì dataset handling  \n",
        "- `pandas` ‚Äì CSV loading & exploration  \n",
        "- `sklearn` ‚Äì train/test split & metrics  \n",
        "- `huggingface_hub` ‚Äì upload model to Hugging Face  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da14a3c7",
      "metadata": {
        "id": "da14a3c7"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets huggingface_hub accelerate scikit-learn pandas kagglehub\n",
        "!pip uninstall -y transformers\n",
        "!pip uninstall -y tensorflow tensorflow-text keras\n",
        "!pip install -U transformers accelerate datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130085d0",
      "metadata": {
        "id": "130085d0"
      },
      "source": [
        "## ‚úÖ Step 1: Imports & device check\n",
        "\n",
        "If this cell runs, your environment is ready.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa09c382",
      "metadata": {
        "id": "aa09c382"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        ")\n",
        "\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49115221",
      "metadata": {
        "id": "49115221"
      },
      "source": [
        "## ‚úÖ Step 2: Load the Kaggle Resume Dataset\n",
        "\n",
        "We'll use this dataset from Kaggle:  \n",
        "\n",
        "**Kaggle dataset:** <https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset>\n",
        "\n",
        "\n",
        "The dataset typically contains columns like:\n",
        "\n",
        "- `ID` ‚Äì unique identifier  \n",
        "- `Resume_str` ‚Äì resume text as plain string  \n",
        "- `Resume_html` ‚Äì resume in HTML format  \n",
        "- `Category` ‚Äì job category label (e.g., `Data Science`, `HR`, etc.)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaee7948",
      "metadata": {
        "id": "aaee7948"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"snehaanbhawal/resume-dataset\")\n",
        "print(\"üìÅ Dataset downloaded to:\", path)\n",
        "\n",
        "# Try to locate a CSV file automatically\n",
        "csv_file = None\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(\".csv\"):\n",
        "            csv_file = os.path.join(root, f)\n",
        "            break\n",
        "    if csv_file:\n",
        "        break\n",
        "\n",
        "if not csv_file:\n",
        "    raise FileNotFoundError(\n",
        "        f\"No CSV found in dataset folder: {path}. \"\n",
        "        \"Check Kaggle dataset structure.\"\n",
        ")\n",
        "\n",
        "print(\"üìÑ Using CSV file:\", csv_file)\n",
        "\n",
        "# Load into DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "print(\"Dataframe shape:\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ee601e",
      "metadata": {
        "id": "d5ee601e"
      },
      "source": [
        "## üîç Step 3: Explore the dataset & basic bias signals\n",
        "\n",
        "We‚Äôll take a quick look at:\n",
        "\n",
        "- Column names  \n",
        "- Example rows  \n",
        "- How many resumes per `Category`  \n",
        "- Basic text length stats\n",
        "\n",
        "This is a **very shallow** view, but even this can show **representation imbalance** (e.g., some categories heavily overrepresented)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b91e1f7",
      "metadata": {
        "id": "1b91e1f7"
      },
      "outputs": [],
      "source": [
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Drop rows with missing text or labels\n",
        "df = df.dropna(subset=[\"Resume_str\", \"Category\"])\n",
        "\n",
        "print(\"\\nNumber of rows after dropping missing:\", len(df))\n",
        "\n",
        "print(\"\\nCategory value counts:\")\n",
        "print(df[\"Category\"].value_counts())\n",
        "\n",
        "# Add a simple text length column\n",
        "df[\"text_length\"] = df[\"Resume_str\"].str.len()\n",
        "print(\"\\nText length stats:\")\n",
        "print(df[\"text_length\"].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac155835",
      "metadata": {
        "id": "ac155835"
      },
      "source": [
        "## ‚úÖ Step 4: Prepare data for BERT fine-tuning\n",
        "\n",
        "We‚Äôll:\n",
        "\n",
        "1. Use the `Resume_str` column as the input text  \n",
        "2. Use `Category` as the label  \n",
        "3. Map each unique category to an integer ID  \n",
        "4. Split into **train** and **validation** sets  \n",
        "5. Wrap everything into a Hugging Face `Dataset`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c61230",
      "metadata": {
        "id": "c4c61230"
      },
      "outputs": [],
      "source": [
        "# Use these column names (change here if your CSV differs)\n",
        "TEXT_COL = \"Resume_str\"\n",
        "LABEL_COL = \"Category\"\n",
        "\n",
        "# Create label mappings\n",
        "label_list = sorted(df[LABEL_COL].unique())\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "print(\"Number of labels:\", len(label_list))\n",
        "print(\"Example label mapping (first 10):\", list(label2id.items())[:10])\n",
        "\n",
        "df[\"label\"] = df[LABEL_COL].map(label2id)\n",
        "\n",
        "# Train/validation split\n",
        "train_df, val_df = train_test_split(\n",
        "    df[[TEXT_COL, \"label\"]],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Validation size:\", len(val_df))\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16968d9a",
      "metadata": {
        "id": "16968d9a"
      },
      "source": [
        "## ‚úÖ Step 5: Tokenize text for BERT\n",
        "\n",
        "We‚Äôll use the base BERT model:\n",
        "\n",
        "- Model checkpoint: `bert-base-uncased`\n",
        "\n",
        "We will:\n",
        "\n",
        "- Tokenize the resume text  \n",
        "- Truncate long resumes to a max length (e.g. 256 tokens to keep training fast in a workshop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28816291",
      "metadata": {
        "id": "28816291"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "max_length = 256  # keep it small for live training\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch[TEXT_COL],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "train_ds_tok = train_ds.map(tokenize_batch, batched=True)\n",
        "val_ds_tok = val_ds.map(tokenize_batch, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_ds_tok = train_ds_tok.remove_columns([TEXT_COL])\n",
        "val_ds_tok = val_ds_tok.remove_columns([TEXT_COL])\n",
        "\n",
        "train_ds_tok.set_format(\"torch\")\n",
        "val_ds_tok.set_format(\"torch\")\n",
        "\n",
        "train_ds_tok[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d082b898",
      "metadata": {
        "id": "d082b898"
      },
      "source": [
        "## ‚úÖ Step 6: Load pre-trained BERT for classification\n",
        "\n",
        "We‚Äôll fine-tune:\n",
        "\n",
        "- `bert-base-uncased`  \n",
        "- With `num_labels = number of resume categories`\n",
        "\n",
        "This is where **transfer learning** happens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b9bbe0",
      "metadata": {
        "id": "d7b9bbe0"
      },
      "outputs": [],
      "source": [
        "num_labels = len(label_list)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "print(\"Model loaded on\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5623c845",
      "metadata": {
        "id": "5623c845"
      },
      "source": [
        "## ‚úÖ Step 7: Set up training\n",
        "\n",
        "We‚Äôll use the Hugging Face `Trainer` API for convenience.\n",
        "\n",
        "For a **live workshop**, keep training light:\n",
        "\n",
        "- `num_train_epochs = 1`  \n",
        "- Small batch size (depending on GPU memory)  \n",
        "- This is for **demo**, not production!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2e2c34",
      "metadata": {
        "id": "dd2e2c34"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./resume-bert-output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds_tok,\n",
        "    eval_dataset=val_ds_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Trainer ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b646154a",
      "metadata": {
        "id": "b646154a"
      },
      "source": [
        "## ‚ñ∂Ô∏è Step 8: Train the model (live)\n",
        "\n",
        "Now we fine-tune BERT on the resume dataset.\n",
        "\n",
        "> This step **may take a few minutes** depending on GPU/TPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64793e1f",
      "metadata": {
        "id": "64793e1f"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cea246",
      "metadata": {
        "id": "91cea246"
      },
      "source": [
        "## ‚úÖ Step 9: Evaluate on validation set\n",
        "\n",
        "We‚Äôll get:\n",
        "\n",
        "- Accuracy (from our metric function)  \n",
        "- A full classification report for a deeper look\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ee1227",
      "metadata": {
        "id": "37ee1227"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(\"Eval results:\", eval_results)\n",
        "\n",
        "# Get predictions & classification report\n",
        "preds_output = trainer.predict(val_ds_tok)\n",
        "preds = preds_output.predictions.argmax(axis=-1)\n",
        "true_labels = preds_output.label_ids\n",
        "\n",
        "print(\"\\nDetailed classification report:\")\n",
        "print(classification_report(true_labels, preds, target_names=label_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b9d5dcb",
      "metadata": {
        "id": "9b9d5dcb"
      },
      "source": [
        "## üíæ Step 10: Save fine-tuned model and `.pt` file\n",
        "\n",
        "We‚Äôll:\n",
        "\n",
        "1. Save the full Hugging Face model directory (`save_pretrained`)  \n",
        "2. Save a pure PyTorch `.pt` state dict file  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199b0985",
      "metadata": {
        "id": "199b0985"
      },
      "outputs": [],
      "source": [
        "save_dir = \"resume-bert-finetuned\"\n",
        "trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "# Also save a plain .pt file with state dict\n",
        "pt_path = \"resume_bert_finetuned_state_dict.pt\"\n",
        "torch.save(model.state_dict(), pt_path)\n",
        "\n",
        "print(\"Saved HF model to:\", save_dir)\n",
        "print(\"Saved PyTorch .pt file to:\", pt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda3390b",
      "metadata": {
        "id": "fda3390b"
      },
      "source": [
        "## üéØ Step 11: Simple bias exploration with a BERT-based zero-shot model\n",
        "\n",
        "We‚Äôll use a **BERT-based MNLI model** from Hugging Face as a **zero-shot classifier** to infer **high-level, non-sensitive features** about each resume, such as:\n",
        "\n",
        "- `\"technical\"`  \n",
        "- `\"non-technical\"`  \n",
        "- `\"management\"`  \n",
        "- `\"entry-level\"`  \n",
        "- `\"senior-level\"`  \n",
        "\n",
        "Then we‚Äôll check how these ‚Äúfeatures‚Äù are distributed across categories to see potential **representation imbalances**.\n",
        "\n",
        "Model used (BERT-based MNLI): `ishan/bert-base-uncased-mnli`\n",
        "\n",
        "> ‚ö†Ô∏è Note: This is a **rough heuristic**, not a fairness-certified bias audit. It‚Äôs just a teaching tool to think critically about datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9220646",
      "metadata": {
        "id": "f9220646"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "feature_model_name = \"ishan/bert-base-uncased-mnli\"\n",
        "\n",
        "feature_classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=feature_model_name,\n",
        "    tokenizer=feature_model_name,\n",
        "    device=0 if device == \"cuda\" else -1,\n",
        ")\n",
        "\n",
        "candidate_features = [\"technical\", \"non-technical\", \"management\", \"entry-level\", \"senior-level\"]\n",
        "\n",
        "# Sample a subset for speed\n",
        "sample_df = df.sample(n=min(200, len(df)), random_state=42).copy()\n",
        "\n",
        "feature_labels = []\n",
        "\n",
        "for text in sample_df[TEXT_COL].tolist():\n",
        "    # Keep resumes short-ish for speed\n",
        "    text_short = text[:2000]\n",
        "    result = feature_classifier(\n",
        "        text_short,\n",
        "        candidate_features,\n",
        "        multi_label=False,\n",
        "    )\n",
        "    feature_labels.append(result[\"labels\"][0])\n",
        "\n",
        "sample_df[\"inferred_feature\"] = feature_labels\n",
        "sample_df[[\"Category\", \"inferred_feature\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5964f14",
      "metadata": {
        "id": "a5964f14"
      },
      "source": [
        "### üîé Aggregate ‚Äúfeature‚Äù distributions\n",
        "\n",
        "Now we‚Äôll see:\n",
        "\n",
        "- How often each inferred feature appears overall  \n",
        "- How they are distributed by `Category`  \n",
        "\n",
        "This can highlight where the dataset might be skewed (e.g., certain categories mostly considered ‚Äútechnical‚Äù or ‚Äúentry-level‚Äù)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bokeh\n",
        "\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import cumsum\n",
        "from bokeh.palettes import Category10, Category20\n",
        "from bokeh.layouts import gridplot\n",
        "import numpy as np\n",
        "\n",
        "output_notebook()  # render bokeh plots inline in Colab"
      ],
      "metadata": {
        "id": "N9ghkMPulqI3"
      },
      "id": "N9ghkMPulqI3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcd05ebb",
      "metadata": {
        "id": "fcd05ebb"
      },
      "outputs": [],
      "source": [
        "print(\"Overall inferred feature distribution:\")\n",
        "print(sample_df[\"inferred_feature\"].value_counts())\n",
        "\n",
        "print(\"\\nFeature distribution by Category:\")\n",
        "cross_tab = pd.crosstab(sample_df[\"Category\"], sample_df[\"inferred_feature\"], normalize=\"index\")\n",
        "cross_tab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Interactive bias visualization with Bokeh\n",
        "# ==============================\n",
        "\n",
        "# Overall counts of inferred features\n",
        "overall_counts = sample_df[\"inferred_feature\"].value_counts()\n",
        "\n",
        "# Normalized feature distribution by Category (proportions)\n",
        "cross_tab = pd.crosstab(\n",
        "    sample_df[\"Category\"],\n",
        "    sample_df[\"inferred_feature\"],\n",
        "    normalize=\"index\"\n",
        ")\n",
        "\n",
        "print(\"Categories:\", list(cross_tab.index))\n",
        "print(\"Inferred features:\", list(cross_tab.columns))\n",
        "\n",
        "# ---------- Overall pie chart (all resumes) ----------\n",
        "overall_df = overall_counts.reset_index()\n",
        "overall_df.columns = [\"feature\", \"count\"]\n",
        "overall_df[\"proportion\"] = overall_df[\"count\"] / overall_df[\"count\"].sum()\n",
        "overall_df[\"angle\"] = overall_df[\"proportion\"] * 2 * np.pi\n",
        "\n",
        "# Choose a color palette large enough\n",
        "palette = Category10[10] if len(overall_df) <= 10 else Category20[20]\n",
        "overall_df[\"color\"] = [palette[i % len(palette)] for i in range(len(overall_df))]\n",
        "\n",
        "p_overall = figure(\n",
        "    height=350,\n",
        "    width=400,\n",
        "    title=\"Overall inferred feature distribution\",\n",
        "    tools=\"hover\",\n",
        "    tooltips=\"@feature: @proportion{0.0%}\",\n",
        "    x_range=(-1, 1),\n",
        "    y_range=(-1, 1),\n",
        ")\n",
        "\n",
        "p_overall.wedge(\n",
        "    x=0,\n",
        "    y=0,\n",
        "    radius=0.8,\n",
        "    start_angle=cumsum(\"angle\", include_zero=True),\n",
        "    end_angle=cumsum(\"angle\"),\n",
        "    line_color=\"white\",\n",
        "    fill_color=\"color\",\n",
        "    legend_field=\"feature\",\n",
        "    source=overall_df,\n",
        ")\n",
        "\n",
        "p_overall.legend.location = \"right\"\n",
        "\n",
        "# ---------- Pie chart per Category ----------\n",
        "category_figs = []\n",
        "categories = list(cross_tab.index)\n",
        "features = list(cross_tab.columns)\n",
        "\n",
        "for cat_idx, cat in enumerate(categories):\n",
        "    row = cross_tab.loc[cat].reset_index()\n",
        "    row.columns = [\"feature\", \"proportion\"]\n",
        "\n",
        "    # Skip completely empty rows (just in case)\n",
        "    if row[\"proportion\"].sum() == 0:\n",
        "        continue\n",
        "\n",
        "    row[\"angle\"] = row[\"proportion\"] * 2 * np.pi\n",
        "    row[\"color\"] = [palette[i % len(palette)] for i in range(len(row))]\n",
        "\n",
        "    p_cat = figure(\n",
        "        height=250,\n",
        "        width=250,\n",
        "        title=str(cat),\n",
        "        tools=\"hover\",\n",
        "        tooltips=\"@feature: @proportion{0.0%}\",\n",
        "        x_range=(-1, 1),\n",
        "        y_range=(-1, 1),\n",
        "    )\n",
        "\n",
        "    p_cat.wedge(\n",
        "        x=0,\n",
        "        y=0,\n",
        "        radius=0.8,\n",
        "        start_angle=cumsum(\"angle\", include_zero=True),\n",
        "        end_angle=cumsum(\"angle\"),\n",
        "        line_color=\"white\",\n",
        "        fill_color=\"color\",\n",
        "        source=row,\n",
        "    )\n",
        "\n",
        "    category_figs.append(p_cat)\n",
        "\n",
        "# Arrange category pies in a grid (3 per row)\n",
        "grid = gridplot(category_figs, ncols=3)\n",
        "\n",
        "# Show overall pie + grid of per-category pies\n",
        "show(grid)\n",
        "show(p_overall)"
      ],
      "metadata": {
        "id": "vvK19aYdluIY"
      },
      "id": "vvK19aYdluIY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f0540a3f",
      "metadata": {
        "id": "f0540a3f"
      },
      "source": [
        "## ‚òÅÔ∏è Step 12: Push the `.pt` model to a **private Hugging Face repo**\n",
        "\n",
        "### One-time setup (in browser)\n",
        "\n",
        "1. Go to <https://huggingface.co> and create an account (if you don‚Äôt already have one).  \n",
        "2. Go to **Settings ‚Üí Access Tokens** and create a token with **`write`** permissions.  \n",
        "3. Keep the token ready (you‚Äôll paste it into Colab, it won‚Äôt be saved in the notebook).\n",
        "\n",
        "### In this notebook\n",
        "\n",
        "We will:\n",
        "\n",
        "1. Log in programmatically by saving the token securely.  \n",
        "2. Create (or reuse) a **private** model repo.  \n",
        "3. Upload the `.pt` file and optionally the full HF model directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82f9d4e",
      "metadata": {
        "id": "f82f9d4e"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# üîê 1. Save your Hugging Face token locally in the Colab session\n",
        "if not HfFolder.get_token():\n",
        "    hf_token = getpass(\"Enter your Hugging Face token (with write permissions): \")\n",
        "    HfFolder.save_token(hf_token)\n",
        "else:\n",
        "    print(\"Hugging Face token already set for this session.\")\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# üîß 2. Set your repo info here\n",
        "HF_USERNAME = \"kevinbjoseph\"   # <-- CHANGE THIS\n",
        "HF_MODEL_REPO = \"resume-bert-demo-12-1\" # <-- CHANGE THIS if you like\n",
        "\n",
        "repo_id = f\"{HF_USERNAME}/{HF_MODEL_REPO}\"\n",
        "\n",
        "# Create repo if it doesn't exist (private=True)\n",
        "api.create_repo(repo_id=repo_id, private=True, exist_ok=True)\n",
        "print(\"Using Hugging Face repo:\", repo_id)\n",
        "\n",
        "# 3. Upload the .pt file\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"resume_bert_finetuned_state_dict.pt\",\n",
        "    path_in_repo=\"resume_bert_finetuned_state_dict.pt\",\n",
        "    repo_id=repo_id,\n",
        ")\n",
        "\n",
        "# 4. Optionally upload the full HF model directory\n",
        "# (this lets you later call `from_pretrained(repo_id)` easily)\n",
        "for root, dirs, files in os.walk(save_dir):\n",
        "    for file in files:\n",
        "        local_path = os.path.join(root, file)\n",
        "        rel_path_in_repo = os.path.relpath(local_path, save_dir)\n",
        "        repo_path = f\"{rel_path_in_repo}\"\n",
        "        print(f\"Uploading {local_path} -> {repo_path}\")\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=local_path,\n",
        "            path_in_repo=repo_path,\n",
        "            repo_id=repo_id,\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ Upload complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3fedc3e",
      "metadata": {
        "id": "f3fedc3e"
      },
      "source": [
        "## üêô Step 13: Put this notebook into your own GitHub repo\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5fed6f0",
      "metadata": {
        "id": "e5fed6f0"
      },
      "source": [
        "## üéâ Wrap-Up\n",
        "\n",
        "In this notebook, you:\n",
        "\n",
        "- Loaded the **Kaggle resume dataset**  \n",
        "- Fine-tuned a **BERT text classifier** on resume text  \n",
        "- Saved the model as a **Hugging Face-style directory** and a **`.pt` file**  \n",
        "- Used a **BERT-based MNLI model** to infer high-level, non-sensitive ‚Äúfeatures‚Äù and inspect basic dataset bias patterns  \n",
        "- Uploaded your model to a **private Hugging Face model repo**  \n",
        "- Learned two ways to put the notebook into **GitHub**\n",
        "\n",
        "This is a **starting point** for thinking about:\n",
        "\n",
        "- How dataset composition affects models  \n",
        "- How to responsibly handle model + data sharing  \n",
        "- How to structure a small NLP project end-to-end  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}